{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6394938e-49f7-4e25-a44b-3e65197bb544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import gc\n",
    "import glob\n",
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from transformers import AutoTokenizer, AutoModel, RobertaTokenizer, RobertaForSequenceClassification, RobertaConfig\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler, TensorDataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fa56f3-174a-42ee-b2b5-53d06935fa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefectModel(nn.Module):\n",
    "    def __init__(self, encoder, config, tokenizer, cfg):\n",
    "        super(DefectModel, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.config = config\n",
    "        self.tokenizer = tokenizer\n",
    "        self.cfg = cfg\n",
    "\n",
    "    def get_roberta_vec(self, source_ids, labels):\n",
    "        attention_mask = source_ids.ne(self.tokenizer.pad_token_id)\n",
    "        outputs = self.encoder(input_ids=source_ids, \n",
    "                               attention_mask=attention_mask,\n",
    "                               labels=labels,\n",
    "                               output_hidden_states=True)\n",
    "        hidden_states = outputs['hidden_states'][-1]\n",
    "        eos_mask = source_ids.eq(self.config.eos_token_id)\n",
    "\n",
    "        if len(torch.unique(eos_mask.sum(1))) > 1:\n",
    "            raise ValueError(\"All examples must have the same number of <eos> tokens.\")\n",
    "        vec = hidden_states[eos_mask, :].view(hidden_states.size(0), -1,\n",
    "                                              hidden_states.size(-1))[:, -1, :]\n",
    "        return vec\n",
    "\n",
    "    def forward(self, source_ids=None, labels=None):\n",
    "        source_ids = source_ids.view(-1, self.cfg['max_source_length'])\n",
    "\n",
    "        vec = self.get_roberta_vec(source_ids, labels)\n",
    "\n",
    "        return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4ddd69-09e4-441b-98d2-e6fc4ff17ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filenames(num):\n",
    "    data_dir = f'data_processed/{Folders[num]}/roberta/data.csv'\n",
    "    return data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb98197f-e4b4-4607-8ad2-19f2868ec559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_defect_examples(filename, data_num):\n",
    "    examples = []\n",
    "    data = pd.read_csv(filename)\n",
    "    for i in data.iterrows():\n",
    "        code = ' '.join(i[1]['text'].split())\n",
    "        examples.append(\n",
    "            Data(\n",
    "                idx=i[0],\n",
    "                source=code,\n",
    "                target=i[1]['label']\n",
    "            )\n",
    "        )\n",
    "        if i[0] + 1 == data_num:\n",
    "            break\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be0b04a-a3b4-4ceb-80b1-1c40bd833a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(object):\n",
    "    def __init__(self,\n",
    "                 idx,\n",
    "                 source,\n",
    "                 target\n",
    "                 ):\n",
    "        self.idx = idx\n",
    "        self.source = source\n",
    "        self.target = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c26ba75-585c-45a3-9d7d-312bc30d9a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_defect_examples_to_features(item):\n",
    "    example, example_index, tokenizer, cfg = item\n",
    "    source_str = example.source\n",
    "    code = tokenizer.encode(source_str, max_length=cfg['max_source_length'], padding='max_length', truncation=True)\n",
    "    return DefectInputFeatures(example_index, code, example.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1def16d6-7fe4-4acd-a885-af2d90000ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefectInputFeatures(object):\n",
    "    def __init__(self,\n",
    "                 example_id,\n",
    "                 source_ids,\n",
    "                 label\n",
    "                 ):\n",
    "        self.example_id = example_id\n",
    "        self.source_ids = source_ids\n",
    "        self.label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc341824-f69d-452c-bb08-46083024a248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_cache_defect_data(cfg, filename, tokenizer, split_tag, is_sample=False):\n",
    "    cache_fn = os.path.join(cfg['cache_path'], split_tag)\n",
    "    examples = read_defect_examples(filename, cfg['data_num'])\n",
    "    if is_sample:\n",
    "        examples = random.sample(examples, int(len(examples) * 0.1))\n",
    "\n",
    "    if os.path.exists(cache_fn):\n",
    "        print(f'Loading data from {cache_fn}')\n",
    "        data = torch.load(cache_fn)\n",
    "    else:\n",
    "        if is_sample:\n",
    "            print(f\"Sample 10 percent of data from {filename}\")\n",
    "        elif cfg['data_num'] == -1:\n",
    "            print(f\"Create cache data into {cache_fn}\")\n",
    "        tuple_examples = [(example, idx, tokenizer, cfg) for idx, example in enumerate(examples)]\n",
    "        features = [convert_defect_examples_to_features(example) \n",
    "                    for example in tqdm(tuple_examples, total=len(tuple_examples))]\n",
    "        all_source_ids = torch.tensor([f.source_ids for f in features], dtype=torch.long)\n",
    "        all_labels = torch.tensor([f.label for f in features], dtype=torch.long)\n",
    "        data = TensorDataset(all_source_ids, all_labels)\n",
    "\n",
    "        if cfg['data_num'] == -1:\n",
    "            torch.save(data, cache_fn)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39550940-7501-44a6-8ff2-c1c11162df4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfg = dict(\n",
    "    name = 'roberta-base',\n",
    "    dataset='ffmq',\n",
    "    max_source_length = 32,\n",
    "    cache_path = 'cache',\n",
    "    data_num = -1,\n",
    "    train_batch_size = 8,\n",
    "    eval_batch_size = 8,\n",
    "    num_train_epochs = 4,\n",
    "    weight_decay = 0.0,\n",
    "    learning_rate = 5e-5,\n",
    "    adam_epsilon = 1e-8,\n",
    "    warmup_steps = 100,\n",
    "    gradient_accumulation_steps = 1,\n",
    "    max_grad_norm = 1.0,\n",
    "    do_eval = True,\n",
    "    do_test = True,\n",
    "    output_dir = 'results',\n",
    "    save_last_checkpoints = True,\n",
    "    start_epoch = 0,\n",
    "    patience = 2,\n",
    ")\n",
    "Folders = ['Verum', 'FFMpeg_Qemu']\n",
    "cfg['device'] = 'cpu'\n",
    "\n",
    "config_class, model_class, tokenizer_class = RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer\n",
    "config = config_class.from_pretrained(cfg['name'])\n",
    "model = model_class.from_pretrained(cfg['name'])\n",
    "tokenizer = tokenizer_class.from_pretrained(cfg['name'])\n",
    "model = DefectModel(model, config, tokenizer, cfg)\n",
    "model.to(cfg['device'])\n",
    "\n",
    "cfg['train_filename'] = get_filenames(1)\n",
    "data_tag = f'{cfg[\"dataset\"]}_{cfg[\"max_source_length\"]}_full_data'\n",
    "data = load_and_cache_defect_data(cfg, cfg['train_filename'],tokenizer, data_tag, is_sample=False)\n",
    "data_sampler = RandomSampler(data)\n",
    "dataloader = DataLoader(data, sampler=data_sampler, batch_size=cfg['train_batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8224da-cfd5-4331-857d-c96cc664be48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bar = tqdm(dataloader, total=len(dataloader), desc=\"Training\")\n",
    "for step, batch in enumerate(bar):\n",
    "    batch = tuple(t.to(cfg['device']) for t in batch)\n",
    "    source_ids, labels = batch\n",
    "    vec = model(source_ids, labels)\n",
    "    torch.save(vec, f\"data_processed/FFMpeg_Qemu/tensor/{step}.t\")\n",
    "    del vec, batch, source_ids, labels\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ae294c-187e-4cf2-a4e2-aa45bb664485",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_lists = glob.glob('data_processed/FFMpeg_Qemu/tensor/*')\n",
    "for step, file in tqdm(enumerate(file_lists), total=len(file_lists), desc='Concatenating'):\n",
    "    tensor = torch.load(file)\n",
    "    if step == 0:\n",
    "        df = tensor\n",
    "    else:\n",
    "        df = torch.cat((df, tensor))\n",
    "    del tensor\n",
    "    gc.collect()\n",
    "torch.save(df, f'data_processed/FFMpeg_Qemu/roberta/x256/data.t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ce24bd-06c9-4ae4-8cef-bb05124fa8b3",
   "metadata": {},
   "source": [
    "# ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a6fe6c-6770-45fc-9f49-2482e2837c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.load('data_processed/FFMpeg_Qemu/roberta/x32/data.t').detach().numpy()\n",
    "y = torch.load('data_processed/FFMpeg_Qemu/roberta/label.t').numpy()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f39f359-3778-4ae8-ab0b-1eb4b7b56069",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFMQDataLoader:\n",
    "    def __init__(self, data, labels, batch_size, shuffle=True):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(data))\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "        for start_idx in range(0, len(self.data), self.batch_size):\n",
    "            batch_indexes = self.indexes[start_idx:start_idx + self.batch_size]\n",
    "            batch_data = self.data[batch_indexes]\n",
    "            batch_labels = self.labels[batch_indexes]\n",
    "\n",
    "            yield torch.tensor(batch_data), torch.tensor(batch_labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) // self.batch_size\n",
    "\n",
    "train_loader = FFMQDataLoader(x_train, y_train, 64)\n",
    "test_loader = FFMQDataLoader(x_test, y_test, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b7a0c1-8bb3-4c44-b966-dacc8bb6450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_results = pd.DataFrame(columns=['hidden_size', 'layers', 'dropout', 'lr', 'loss',\n",
    "                                   'epochs', 'accuracy', 'precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0938b0-6c7d-4431-ac41-848db7371bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'hidden_size': 256,\n",
    "    'dropout': 0.3,\n",
    "    'layers': 3,\n",
    "    'epochs': 300,\n",
    "    'lr': 0.01\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d422f8-a2de-46f6-b1fd-e88846bbbb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the MLP model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, dropout):\n",
    "        super(MLP, self).__init__()\n",
    "        # Define fully connected layer 1\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        # Define fully connected layer 2\n",
    "        self.fc2 = nn.Linear(hidden_size, int(hidden_size / 2))\n",
    "        # Define fully connected layer 3\n",
    "        self.fc3 = nn.Linear(int(hidden_size / 2), num_classes)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.softmax(self.fc3(x), dim=1)\n",
    "        return x\n",
    "\n",
    "# Instantiate the MLP model\n",
    "input_size = x.shape[1] # 768\n",
    "num_classes = 2\n",
    "model = MLP(input_size, parameters['hidden_size'], num_classes, parameters['dropout'])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=parameters['lr'], momentum=0.9)\n",
    "device='cpu'\n",
    "for epoch in tqdm(range(parameters['epochs'])):\n",
    "    for data, labels in train_loader:\n",
    "        \n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print(f'Loss: {loss.item()}')\n",
    "\n",
    "# Evaluate the model on the testing data\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for data, labels in test_loader:\n",
    "        data = data\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        y_true += labels.tolist()\n",
    "        y_pred += predicted.tolist()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy of the model on the 10000 test source codes: {accuracy} %')\n",
    "\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "    print(f'Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d576546c-e433-4c79-9036-5199b35d7f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters['loss'] = loss.item()\n",
    "parameters['accuracy'] = accuracy\n",
    "parameters['precision'] = precision\n",
    "parameters['recall'] = recall\n",
    "parameters['f1'] = f1_score\n",
    "mlp_results.loc[len(mlp_results)] = parameters\n",
    "mlp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e1db3e-b3ca-426f-a58a-d168f32d78d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_results = pd.DataFrame(columns=['n_estimators', 'max_depth', 'scale_pos_weight', 'learning_rate', 'gamma',\n",
    "                                   'subsample', 'min_child_weight', 'colsample_bytree', 'max_delta_step', \n",
    "                                    'accuracy', 'precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0e8edd-6e49-4867-ad85-4c8e69046fd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "XGB_CONFIG = dict(\n",
    "    n_estimators=100,\n",
    "    max_depth=10, \n",
    "    scale_pos_weight=5,\n",
    "    learning_rate=0.2, \n",
    "    subsample=0.6,\n",
    "    min_child_weight=1,\n",
    "    colsample_bytree=0.8,\n",
    "    gamma=1,\n",
    "    max_delta_step=1\n",
    ")\n",
    "\n",
    "model = XGBClassifier(\n",
    "                      n_estimators=XGB_CONFIG['n_estimators'], \n",
    "                      max_depth=XGB_CONFIG['max_depth'],\n",
    "                      scale_pos_weight=XGB_CONFIG['scale_pos_weight'],\n",
    "                      learning_rate=XGB_CONFIG['learning_rate'], \n",
    "                      subsample=XGB_CONFIG['subsample'], \n",
    "                      min_child_weight=XGB_CONFIG['min_child_weight'], \n",
    "                      colsample_bytree=XGB_CONFIG['colsample_bytree'], \n",
    "                      gamma=XGB_CONFIG['gamma'],\n",
    "                      max_delta_step=XGB_CONFIG['max_delta_step'],\n",
    "                      objective='binary:logistic',\n",
    "                      random_state=42, \n",
    "                      n_jobs=-1)\n",
    "\n",
    "eval_set=[(x_test, y_test)]\n",
    "history = model.fit(x_train, y_train, eval_set=eval_set, eval_metric='error', verbose=20)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "scores = {'accuracy': accuracy_score(y_test, y_pred), 'precision': precision_score(y_test, y_pred), \n",
    "          'recall': recall_score(y_test, y_pred), 'f1': f1_score(y_test, y_pred)}\n",
    "\n",
    "XGB_CONFIG.update(scores)\n",
    "xgb_results = xgb_results.append(XGB_CONFIG, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c58be8-3d50-4a71-9086-1e76ddcdd102",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_results.sort_values(['f1', 'recall', 'accuracy', 'precision'], ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07a5209-1867-4331-ac4d-25f3fcd6ddd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_results = pd.DataFrame(columns=['max_depth', 'learning_rate', 'num_leaves', 'feature_fraction',\n",
    "                                   'subsample', 'num_iterations', 'scale_pos_weight', 'accuracy', 'precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ef9eb0-3136-4bb5-be35-5c54e7361f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LGB_CONFIG_FINE_TUNED = dict(\n",
    "    max_depth=6,\n",
    "    learning_rate=0.01,\n",
    "    num_leaves=3,\n",
    "    feature_fraction=0.9,\n",
    "    subsample=0.8,\n",
    "    num_iterations=100,\n",
    "    scale_pos_weight=2\n",
    ")\n",
    "LGB_CONFIG_FIXED = dict(\n",
    "    objective='binary', \n",
    "    metric='auc',\n",
    "    boosting_type='gbdt',\n",
    ")\n",
    "lgb = LGBMClassifier( \n",
    "                     objective=LGB_CONFIG_FIXED['objective'], \n",
    "                     metric=LGB_CONFIG_FIXED['metric'],\n",
    "                     boosting_type=LGB_CONFIG_FIXED['boosting_type'], \n",
    "                     num_iterations=LGB_CONFIG_FINE_TUNED['num_iterations'], \n",
    "                     learning_rate=LGB_CONFIG_FINE_TUNED['learning_rate'], \n",
    "                     max_depth=LGB_CONFIG_FINE_TUNED['max_depth'], \n",
    "                     num_leaves=LGB_CONFIG_FINE_TUNED['num_leaves'], \n",
    "                     feature_fraction=LGB_CONFIG_FINE_TUNED['feature_fraction'], \n",
    "                     subsample=LGB_CONFIG_FINE_TUNED['subsample'],\n",
    "                     scale_pos_weight=LGB_CONFIG_FINE_TUNED['scale_pos_weight'])\n",
    "history = lgb.fit(x_train, y_train, eval_set=[(x_test, y_test)], verbose=30, early_stopping_rounds=50)\n",
    "y_pred = lgb.predict(x_test)\n",
    "scores = {'accuracy': accuracy_score(y_test, y_pred), 'precision': precision_score(y_test, y_pred), \n",
    "          'recall': recall_score(y_test, y_pred), 'f1': f1_score(y_test, y_pred)}\n",
    "LGB_CONFIG_FINE_TUNED.update(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eb935b-d8a7-4418-a292-71ff2b2c8257",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_results = lgb_results.append(LGB_CONFIG_FINE_TUNED, ignore_index=True)\n",
    "lgb_results.sort_values(['f1', 'recall', 'precision', 'accuracy'], ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edbd998-084f-4c73-8544-d60a425fa74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_results = pd.DataFrame(columns=['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', \n",
    "                                   'max_features', 'bootstrap', 'class_weight', 'accuracy', 'precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39dbf81-1278-4d82-94f5-01ac3c74d262",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_CONFIG = dict(\n",
    "    n_estimators=60,\n",
    "    max_depth=5, \n",
    "    min_samples_split=4,\n",
    "    min_samples_leaf=3,\n",
    "    max_features=None,\n",
    "    bootstrap=True,\n",
    "    class_weight={0: 1, 1: 1.2}\n",
    ")\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=RF_CONFIG['n_estimators'], \n",
    "                               max_depth=RF_CONFIG['max_depth'], \n",
    "                               min_samples_split=RF_CONFIG['min_samples_split'], \n",
    "                               min_samples_leaf=RF_CONFIG['min_samples_leaf'], \n",
    "                               max_features=RF_CONFIG['max_features'], \n",
    "                               bootstrap=RF_CONFIG['bootstrap'], \n",
    "                               class_weight=RF_CONFIG['class_weight'],\n",
    "                               n_jobs=-1, \n",
    "                               random_state=42)\n",
    "\n",
    "history = model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "scores = {'accuracy': accuracy_score(y_test, y_pred), 'precision': precision_score(y_test, y_pred), \n",
    "          'recall': recall_score(y_test, y_pred), 'f1': f1_score(y_test, y_pred)}\n",
    "\n",
    "RF_CONFIG.update(scores)\n",
    "rf_results = rf_results.append(RF_CONFIG, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b19999-24b9-4cac-896c-71fbba044637",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_results.sort_values(['f1', 'recall', 'precision', 'accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79331c5f-bc19-4dd6-9608-d3176c86eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_results = pd.DataFrame(columns=['max_depth', 'min_samples_split', 'min_samples_leaf', \n",
    "                                   'max_features', 'class_weight', 'accuracy', 'precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161db137-92e5-4878-959c-62d8d28689a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_CONFIG = dict(\n",
    "    max_depth=5, \n",
    "    min_samples_split=3,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    class_weight={0: 1, 1: 1.2}\n",
    ")\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=DT_CONFIG['max_depth'], \n",
    "                               min_samples_split=DT_CONFIG['min_samples_split'], \n",
    "                               min_samples_leaf=DT_CONFIG['min_samples_leaf'], \n",
    "                               max_features=DT_CONFIG['max_features'],\n",
    "                               class_weight=DT_CONFIG['class_weight'],\n",
    "                               random_state=42)\n",
    "\n",
    "history = model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "scores = {'accuracy': accuracy_score(y_test, y_pred), 'precision': precision_score(y_test, y_pred), \n",
    "          'recall': recall_score(y_test, y_pred), 'f1': f1_score(y_test, y_pred)}\n",
    "\n",
    "DT_CONFIG.update(scores)\n",
    "dt_results = dt_results.append(DT_CONFIG, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309a8eff-0a42-4b3d-844b-1a9610c4bea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_results.sort_values(['f1', 'recall', 'precision', 'accuracy'], ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
